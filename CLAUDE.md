# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**Scribe** - A cold email generation platform for academic research outreach. The application uses FastAPI backend with Supabase authentication and PostgreSQL database, featuring a multi-step agentic pipeline for generating personalized emails.

**Tech Stack:**
- Backend: FastAPI, SQLAlchemy, Alembic, Python 3.13
- Database: Supabase/PostgreSQL with direct connection
- Authentication: Supabase Auth with JWT validation
- AI/ML: Anthropic Claude API, OpenAI (legacy)
- Web Scraping: Playwright (headless browser), scholarly

## Development Commands

### Running the Application

```bash
# Start development server (with hot reload)
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Or using the main.py directly
python main.py

# Production (as per Procfile)
uvicorn main:app --host 0.0.0.0 --port $PORT --timeout-keep-alive 120
```

### Database Management

```bash
# Create a new migration after model changes
alembic revision --autogenerate -m "Description of changes"

# Apply migrations to database
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# View current migration version
alembic current

# View migration history
alembic history --verbose
```

**Notes:**
- Playwright is used for web scraping with JavaScript support
- Browsers run in headless mode (no GUI)
- For serverless/container deployments, use `--no-sandbox` flag (already configured)
- Browser binaries are ~300MB, ensure sufficient disk space

### Testing

**IMPORTANT**: Always use the virtual environment's Python to run tests.

```bash
# Activate virtual environment first
source venv/bin/activate

# Run all tests
pytest

# Run tests in a specific directory
pytest pipeline/steps/template_parser/

# Run a specific test file
pytest pipeline/steps/template_parser/test_template_parser.py

# Run a specific test function
pytest pipeline/steps/template_parser/test_template_parser.py::test_logging_research_template

# Run tests with markers
pytest -m unit              # Run only unit tests
pytest -m "not slow"        # Skip slow tests
pytest -m integration       # Run only integration tests

# Run with verbose output
pytest -v

# Run with output capture disabled (see print statements)
pytest -s

# Run and show coverage report
pytest --cov=pipeline --cov-report=html

# Collect tests without running (useful for debugging)
pytest --collect-only
```

**Test Configuration:**
- `pytest.ini` - Pytest configuration (markers, paths, async settings)
- `conftest.py` - Global test fixtures and setup (logfire, paths)
- Individual `conftest.py` in test directories for module-specific fixtures

### Health Checks

```bash
# Health check endpoint
curl http://localhost:8000/health

# API documentation (auto-generated by FastAPI)
# Visit: http://localhost:8000/docs
```

## Architecture

### Backend-First Design

**CRITICAL**: This application follows a **BACKEND-FIRST** architecture:
- Frontend uses Supabase ONLY for authentication (OAuth, JWT)
- Backend handles ALL database operations using Supabase service role key
- Backend validates JWT tokens and extracts user_id from token (never trust request body)
- No direct database access from frontend

### Authentication Flow

```
Frontend (Next.js) -> Supabase Auth (Login/OAuth)
                   -> Get JWT token
                   -> Include token in API requests

Backend (FastAPI)  -> Validate JWT token via Supabase
                   -> Extract user_id from validated token
                   -> Perform database operations
                   -> Return response
```

**Authentication Dependencies** (api/dependencies.py):
- `get_supabase_user`: Validates JWT and returns Supabase user data (id, email)
- `get_current_user`: Fetches user from local database, requires initialization

### Database Models

**Users Table** (models/user.py):
- `id`: UUID from Supabase auth.users (primary key)
- `email`: User email (unique, indexed)
- `display_name`: Optional display name
- `generation_count`: Tracks number of emails generated
- `created_at`: Timestamp

**Emails Table** (models/email.py):
- `id`: Auto-generated UUID
- `user_id`: Foreign key to users table (CASCADE delete)
- `recipient_name`: Professor/recipient name
- `recipient_interest`: Research interest for personalization
- `email_message`: Generated email content
- `created_at`: Timestamp (indexed)

### Pipeline Architecture (In Development)

The email generation system uses a multi-step agentic pipeline located in `pipeline/`:

**Pipeline Steps:**
1. **Template Parser** - Analyzes email templates and extracts search parameters
2. **Web Scraper** - Fetches relevant information based on search terms
3. **ArXiv Helper** - Enriches with academic paper data (for RESEARCH template type)
4. **Email Composer** - Generates final personalized email

**Template Types** (pipeline/models/core.py):
- `RESEARCH`: Includes research papers the professor has written
- `BOOK`: Includes books the professor has written
- `GENERAL`: General information about the professor

**Job Status** (pipeline/models/core.py):
- `PENDING`: Job queued
- `RUNNING`: Currently processing
- `COMPLETED`: Successfully finished
- `FAILED`: Encountered error

### Configuration Management

**Environment Variables** (.env):
- All configuration via `config/settings.py` using Pydantic Settings
- Type-safe validation at startup
- Required variables will cause startup failure if missing

**Key Settings:**
- Database connection string auto-constructed from individual components
- CORS origins parsed from comma-separated string
- Supabase URL and service role key required
- Anthropic API key required for email generation

## API Endpoints

### User Management (`/api/user`)

**POST /api/user/init** - Initialize user profile (idempotent)
- Headers: `Authorization: Bearer {jwt_token}`
- Body: `{ "display_name": string }` (optional)
- Creates user in local database after Supabase auth
- Returns existing user if already initialized

**GET /api/user/profile** - Get current user profile
- Headers: `Authorization: Bearer {jwt_token}`
- Requires user to be initialized first

### Health & Info

**GET /health** - Health check with database status
**GET /** - API information and links to docs

## Development Patterns

### Adding New API Endpoints

1. Define Pydantic schemas in `schemas/` for request/response validation
2. Create route handler in `api/routes/` directory
3. Use authentication dependencies: `Depends(get_current_user)` for protected routes
4. Include router in `main.py` with `app.include_router()`
5. Database operations always in route handler or service layer, never in dependencies

### Database Changes

1. Modify models in `models/` directory (inherit from `Base`)
2. Run `alembic revision --autogenerate -m "description"`
3. Review generated migration in `alembic/versions/`
4. Apply with `alembic upgrade head`
5. Never skip Alembic - always use migrations for schema changes

### Authentication Requirements

**For protected endpoints:**
```python
from api.dependencies import get_current_user
from models.user import User

@router.get("/protected")
async def protected_route(
    current_user: User = Depends(get_current_user)
):
    # current_user is validated and from database
    # User ID is from JWT token, not request body
    pass
```

**NEVER:**
- Trust `user_id` from request body
- Use Supabase anon key in backend
- Allow frontend direct database access

### Pipeline Development

When working with the pipeline system:
1. Each step inherits from `BasePipelineStep` (pipeline/core/runner.py)
2. Implement `execute()` method returning `StepResult`
3. Steps communicate via `PipelineData` dataclass
4. Use structured logging via step logger
5. Handle errors gracefully and return detailed failure information

### Writing Tests

**Test File Organization:**
```
pipeline/steps/template_parser/
├── __init__.py
├── main.py
├── test_template_parser.py        # Main test suite
└── test_template_parser_logging.py # Specific logging tests
```

**Test Structure Best Practices:**

1. **Use proper imports** - Always use absolute imports from project root:
   ```python
   # ✓ CORRECT
   from pipeline.steps.template_parser.main import TemplateParserStep
   from pipeline.models.core import PipelineData

   # ✗ WRONG
   from .main import TemplateParserStep  # Relative imports fail in tests
   ```

2. **Mark async tests** - Use `@pytest.mark.asyncio` for async functions:
   ```python
   @pytest.mark.asyncio
   async def test_async_function():
       result = await some_async_function()
       assert result.success
   ```

3. **Use markers** to categorize tests:
   ```python
   @pytest.mark.unit
   @pytest.mark.asyncio
   async def test_fast_unit_test():
       pass

   @pytest.mark.integration
   @pytest.mark.slow
   async def test_external_api():
       pass
   ```

4. **Leverage fixtures** from conftest.py:
   ```python
   def test_with_fixtures(project_root, mock_env_vars):
       mock_env_vars({"API_KEY": "test-key"})
       # Test code here
   ```

5. **Use logfire spans** for observability:
   ```python
   import logfire

   async def test_with_logging():
       with logfire.span("test_operation"):
           result = await operation()
           logfire.info("Operation completed", result=result)
   ```

**Common Testing Pitfalls:**

❌ **Running tests with system Python**
```bash
# This will fail if pytest not installed globally
python -m pytest test_file.py
pytest test_file.py
```

✅ **Always use virtual environment**
```bash
source venv/bin/activate
pytest test_file.py

# OR use venv directly without activating
venv/bin/pytest test_file.py
```

❌ **Import errors due to missing __init__.py**
- Ensure every package directory has `__init__.py`
- Check `pipeline/`, `pipeline/steps/`, and all subdirectories

✅ **Proper package structure**
```
pipeline/
├── __init__.py          # Required
├── steps/
│   ├── __init__.py      # Required
│   └── template_parser/
│       └── __init__.py  # Required
```

❌ **Running tests from wrong directory**
```bash
cd pipeline/steps/template_parser
pytest test_template_parser.py  # May cause import errors
```

✅ **Always run from project root**
```bash
# From /Users/manitmishra/Desktop/pythonserver
pytest pipeline/steps/template_parser/test_template_parser.py
```

## Project Structure

```
/pythonserver
├── api/                    # FastAPI routes and dependencies
│   ├── routes/            # Route handlers (user.py, etc.)
│   ├── dependencies.py    # Auth dependencies
│   └── legacy/            # Old Flask code (deprecated)
├── models/                # SQLAlchemy ORM models
│   ├── user.py
│   └── email.py
├── schemas/               # Pydantic schemas for validation
│   └── auth.py
├── database/              # Database configuration and utilities
│   ├── base.py           # SQLAlchemy Base and engine
│   ├── session.py        # Session management
│   └── dependencies.py   # Database dependencies
├── services/              # External service integrations
│   └── supabase.py       # Supabase client
├── config/                # Application configuration
│   └── settings.py       # Pydantic Settings
├── pipeline/              # Email generation pipeline (in development)
│   ├── core/             # Pipeline runner and base classes
│   ├── models/           # Pipeline data models
│   └── steps/            # Pipeline step implementations
│       ├── template_parser/
│       ├── web_scraper/
│       ├── arxiv_helper/
│       └── email_composer/
├── alembic/               # Database migrations
│   └── versions/         # Migration files
├── prompts/               # Prompt templates for various tasks
├── main.py               # Application entry point
├── requirements.txt      # Python dependencies
└── alembic.ini          # Alembic configuration
```

## Important Notes

### Security
- Backend uses Supabase service role key (full database access)
- JWT tokens validated on every request
- Row Level Security (RLS) enabled on Supabase tables
- All sensitive credentials in .env (gitignored)

### Database Connection
- Direct PostgreSQL connection to Supabase (not Supabase SDK for queries)
- SQLAlchemy for ORM and query building
- Connection string requires `sslmode=require` for Supabase

### Migration from Firebase
- Original codebase used Firebase (now deprecated)
- All authentication migrated to Supabase
- Some legacy code remains in `api/legacy/` but is not used

### Pipeline Integration
- Pipeline system is under active development
- Will replace current email generation logic
- Uses Pydantic agents for structured workflows
- Designed for Celery worker integration (future)

## Common Workflows

### Adding a New Authenticated Endpoint

1. Create Pydantic schemas in `schemas/`
2. Create route in `api/routes/` using `get_current_user` dependency
3. Test with valid JWT token in Authorization header
4. Update this documentation if endpoint is commonly used

### Modifying Database Schema

1. Edit model in `models/`
2. Generate migration: `alembic revision --autogenerate -m "message"`
3. Review migration file
4. Apply: `alembic upgrade head`
5. Update corresponding Pydantic schemas in `schemas/`

### Debugging Authentication Issues

1. Check `/health` endpoint for Supabase connection status
2. Verify JWT token is valid (check expiration)
3. Ensure user is initialized with POST `/api/user/init`
4. Check server logs for detailed error messages
5. Verify environment variables are loaded correctly

### Writing and Running Tests

1. **Create test file** in the same directory as the code being tested:
   ```bash
   # For pipeline/steps/my_step/main.py, create:
   # pipeline/steps/my_step/test_my_step.py
   ```

2. **Ensure package structure** has all required `__init__.py` files:
   ```bash
   # Check that __init__.py exists in:
   # - pipeline/
   # - pipeline/steps/
   # - pipeline/steps/my_step/
   ```

3. **Write test with proper structure**:
   ```python
   import pytest
   import logfire
   from pipeline.steps.my_step.main import MyStep
   from pipeline.models.core import PipelineData

   @pytest.mark.unit
   @pytest.mark.asyncio
   async def test_my_step():
       step = MyStep()
       data = PipelineData(...)

       with logfire.span("test_my_step"):
           result = await step.execute(data)
           assert result.success
   ```

4. **Run test from project root** using virtual environment:
   ```bash
   source venv/bin/activate
   pytest pipeline/steps/my_step/test_my_step.py -v
   ```

5. **Debug import errors**:
   - Verify you're using `venv/bin/pytest`, not system pytest
   - Check all `__init__.py` files exist in package hierarchy
   - Ensure running from project root (`/pythonserver`)
   - Use `pytest --collect-only` to test import without execution

---

## Documentation

**Comprehensive guides available in the `docs/` folder:**

- **[QUICKSTART.MD](docs/QUICKSTART.MD)** - Get Scribe running in 5 minutes with step-by-step setup
- **[ARCHITECTURE.MD](docs/ARCHITECTURE.MD)** - System design, technology stack, deployment (Render.com), and observability
- **[PIPELINE.MD](docs/PIPELINE.MD)** - Deep dive into the 4-step email generation pipeline with implementation details
- **[DEVELOPMENT.MD](docs/DEVELOPMENT.MD)** - Developer workflows, testing strategies, debugging techniques, and code patterns
- **[API_REFERENCE.MD](docs/API_REFERENCE.MD)** - Complete REST API documentation with authentication, endpoints, and examples

**When to use each guide:**
- **Setting up locally?** → Start with QUICKSTART.MD
- **Understanding the system?** → Read ARCHITECTURE.MD
- **Working on the pipeline?** → Reference PIPELINE.MD
- **Writing code or tests?** → Use DEVELOPMENT.MD
- **Integrating with the API?** → Check API_REFERENCE.MD
