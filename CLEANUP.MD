# Code Quality Cleanup Plan

**Project**: Scribe - Cold Email Generation Platform
**Date**: 2025-11-19
**Audit Score**: 7.5/10 (Good foundation, needs cleanup)
**Total Cleanup Potential**: ~1,000 lines of dead code removal

---

## Executive Summary

This document outlines a comprehensive code quality improvement plan based on a systematic audit of the entire Scribe codebase. The plan is divided into 5 phases, prioritized by security impact, stability risk, and maintenance value.

**Key Metrics**:
- **Dead Code**: 867 lines
- **Security Issues**: 2 (already mitigated - API key revoked)
- **Architecture Improvements**: 4 critical patterns
- **Code Simplifications**: 8 opportunities
- **Best Practice Fixes**: 15+ instances

---

## Table of Contents

1. [Phase 1: Security & Dead Code Removal](#phase-1-security--dead-code-removal)
2. [Phase 2: Architecture Improvements](#phase-2-architecture-improvements)
3. [Phase 3: Code Simplification & DRY Principles](#phase-3-code-simplification--dry-principles)
4. [Phase 4: Best Practices & Code Quality](#phase-4-best-practices--code-quality)
5. [Phase 5: Testing & Validation](#phase-5-testing--validation)
6. [Risk Assessment](#risk-assessment)
7. [Rollback Strategy](#rollback-strategy)

---

## Phase 1: Security & Dead Code Removal

**Priority**: üî¥ CRITICAL
**Estimated Time**: 1 hour
**Risk Level**: Low (no dependencies)
**Impact**: High (security + -867 lines)

#### `pipeline/models/core.py:242-262` (20 lines)
```python
# DELETE THIS BLOCK:
# ===================================================================
# DEPRECATED CLASSES (Legacy - Will be removed in Phase 9)
# ===================================================================
#
# @dataclass
# class PipelineJob:
#     job_id: str
#     status: JobStatus
#     current_step: str = ""
#     ...
```

**Reasoning**: Commented code creates confusion and should be removed. If needed, it exists in git history.

**Risk**: ‚úÖ **NONE** - Already deprecated and commented out

---

### 1.4 Remove Unused Imports

**File**: `models/user.py:7`
```python
# REMOVE THIS:
from typing import List  # Never used in file
```

**Verification**:
```bash
# Use flake8 or ruff to find unused imports
ruff check --select F401 .
```

**Risk**: ‚úÖ **NONE** - No functional impact

---

## Phase 2: Architecture Improvements

**Priority**: üü° HIGH
**Estimated Time**: 2 hours
**Risk Level**: Medium (changes transaction behavior)
**Impact**: High (fixes anti-patterns)

### 2.1 Fix Database Context Manager Auto-Commit

**File**: `database/session.py:14-39`

**Current Code** (‚ùå ANTI-PATTERN):
```python
@contextmanager
def get_db_context() -> Generator[Session, None, None]:
    """Database session context manager with auto-commit."""
    db = SessionLocal()
    try:
        yield db
        db.commit()  # ‚ùå AUTO-COMMITS - dangerous!
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()
```

**Problems**:
1. **Violates Principle of Least Surprise**: Users expect explicit commit control
2. **Commits Read-Only Operations**: Even SELECT queries trigger commit
3. **Difficult to Debug**: Transaction boundaries unclear
4. **Can't Batch Operations**: Forces commit after every context block

**Example of Broken Behavior**:
```python
# User expects this to NOT commit anything:
with get_db_context() as db:
    user = db.query(User).first()  # Just reading
    # Oops! This commits an empty transaction

# User wants to batch multiple operations:
with get_db_context() as db:
    db.add(email1)
    # Can't validate before commit - already committed!
```

**Fixed Code** (‚úÖ CORRECT):
```python
@contextmanager
def get_db_context() -> Generator[Session, None, None]:
    """
    Database session context manager.

    Caller is responsible for calling db.commit() explicitly.
    Automatically rolls back on exception.

    Example:
        with get_db_context() as db:
            db.add(user)
            db.commit()  # Explicit commit
    """
    db = SessionLocal()
    try:
        yield db
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()
```

**Files to Update** (only 2 usages):

1. `pipeline/steps/email_composer/db_utils.py:91-100`
```python
# BEFORE:
with get_db_context() as db:
    user = db.query(User).filter(User.id == user_id).first()
    # Auto-commits here

# AFTER:
with get_db_context() as db:
    user = db.query(User).filter(User.id == user_id).first()
    # No commit needed for read-only operation
```

2. `pipeline/steps/email_composer/db_utils.py:121-133`
```python
# BEFORE:
with get_db_context() as db:
    email = Email(...)
    db.add(email)
    db.flush()
    # Auto-commits here

# AFTER:
with get_db_context() as db:
    email = Email(...)
    db.add(email)
    db.flush()
    db.commit()  # ‚úÖ Explicit commit
```

**Risk**: ‚ö†Ô∏è **MEDIUM** - Changes transaction semantics
- **Mitigation**: Only 2 files use this, easy to verify
- **Testing**: Run full pipeline test to ensure writes still work

---

### 2.2 Add Timeouts to LLM Agent Calls

**Files**: All pipeline steps using `create_agent()`

**Current Code** (‚ùå NO TIMEOUT):
```python
agent = create_agent(
    model=self.model,
    retries=2,
    system_prompt=system_prompt
)
# If API hangs, task hangs forever!
```

**Problem**:
- External API calls can hang indefinitely
- Celery tasks can get stuck in RUNNING state
- No timeout means no guarantee of task completion
- Can exhaust worker pool

**Fixed Code** (‚úÖ WITH TIMEOUT):
```python
agent = create_agent(
    model=self.model,
    retries=2,
    system_prompt=system_prompt,
    timeout=30.0  # 30 second timeout per API call
)
```

**Recommended Timeouts**:
- Template Parser: 30s (simple JSON extraction)
- Web Scraper: 60s (may need to wait for page load)
- Email Composer: 45s (generating email content)

**Files to Update**:
- `pipeline/steps/template_parser/main.py:85`
- `pipeline/steps/email_composer/main.py:248`
- Any other agent creation calls

**Risk**: ‚ö†Ô∏è **LOW** - May need to tune timeout values
- **Mitigation**: Start conservative (60s), reduce based on monitoring
- **Testing**: Test with slow network conditions

---

### 2.3 Standardize UUID Handling

**Problem**: Inconsistent UUID types across the codebase

**Current Inconsistencies**:
```python
# API layer uses strings:
@router.post("/generate/{user_id}")
async def generate_email(user_id: str, ...)  # String

# Database layer uses UUID:
def write_email_to_db(user_id: UUID, ...)  # UUID object

# Tasks layer converts:
user_id_uuid = UUID(user_id)  # Manual conversion
```

**Recommended Standard**:
1. **API Boundary**: Accept `str` in path/query parameters
2. **Internal Processing**: Convert to `UUID` immediately after validation
3. **Database Layer**: Use `UUID` type for all DB operations
4. **Serialization**: Convert back to `str` for JSON responses

**Implementation**:

**Create Utility** (`utils/uuid_helpers.py`):
```python
from uuid import UUID
from typing import Union

def ensure_uuid(value: Union[str, UUID]) -> UUID:
    """Convert string to UUID, or return UUID unchanged."""
    if isinstance(value, UUID):
        return value
    try:
        return UUID(value)
    except ValueError as e:
        raise ValueError(f"Invalid UUID format: {value}") from e

def ensure_str(value: Union[str, UUID]) -> str:
    """Convert UUID to string, or return string unchanged."""
    return str(value)
```

**Update API Routes**:
```python
# Before:
@router.post("/generate/{user_id}")
async def generate_email(user_id: str, ...):
    # Use string directly

# After:
from utils.uuid_helpers import ensure_uuid

@router.post("/generate/{user_id}")
async def generate_email(user_id: str, ...):
    user_uuid = ensure_uuid(user_id)  # Validate early
    # Use user_uuid for all internal operations
```

**Risk**: ‚ö†Ô∏è **MEDIUM** - Touches many files
- **Mitigation**: Create utility first, update incrementally
- **Testing**: Add unit tests for UUID validation

---

### 2.4 Simplify CORS Configuration

**File**: `config/settings.py`

**Problem**: Duplicate parsing logic for CORS origins

**Current Code**:
```python
# Validator parses to list:
@field_validator("allowed_origins")
@classmethod
def parse_origins(cls, v: str) -> List[str]:
    if isinstance(v, str):
        return [origin.strip() for origin in v.split(",") if origin.strip()]
    return v

# Property ALSO parses to list (redundant!):
@property
def cors_origins(self) -> List[str]:
    if isinstance(self.allowed_origins, list):
        return self.allowed_origins
    # This code is unreachable - validator already converted to list!
    return [origin.strip() for origin in self.allowed_origins.split(",") if origin.strip()]
```

**Simplified Code**:
```python
# Keep validator only:
@field_validator("allowed_origins")
@classmethod
def parse_origins(cls, v: str) -> List[str]:
    """Parse comma-separated origins into a list."""
    if isinstance(v, str):
        return [origin.strip() for origin in v.split(",") if origin.strip()]
    return v

# DELETE the property entirely - allowed_origins is already a list!
```

**Update Usage** (`main.py:85`):
```python
# Before:
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,  # Property
    ...
)

# After:
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.allowed_origins,  # Direct field access
    ...
)
```

**Risk**: ‚úÖ **NONE** - Functionally equivalent, just cleaner

---

## Phase 3: Code Simplification & DRY Principles

**Priority**: üü° MEDIUM
**Estimated Time**: 2 hours
**Risk Level**: Low
**Impact**: Medium (maintainability)

### 3.1 Extract Error Formatting Helper

**File**: `api/routes/email.py:158-183`

**Problem**: Celery task error formatting is duplicated and verbose

**Current Code** (‚ùå VERBOSE):
```python
if isinstance(result.info, dict):
    error_msg = result.info.get("exc_message", "Unknown error")
    error_type = result.info.get("exc_type", "Error")
    failed_step = result.info.get("failed_step")
    response_data["error"] = {
        "message": error_msg,
        "type": error_type,
        "failed_step": failed_step
    }
else:
    error_msg = str(result.info) if result.info else "Unknown error"
    response_data["error"] = error_msg
```

**Create Utility** (`utils/celery_helpers.py`):
```python
from typing import Any, Dict, Union

def format_celery_error(result_info: Any) -> Union[Dict[str, Any], str]:
    """
    Format Celery task error information for API responses.

    Args:
        result_info: Error info from AsyncResult.info

    Returns:
        Formatted error dict or string
    """
    if not isinstance(result_info, dict):
        return str(result_info) if result_info else "Unknown error"

    return {
        "message": result_info.get("exc_message", "Unknown error"),
        "type": result_info.get("exc_type", "Error"),
        "failed_step": result_info.get("failed_step")
    }
```

**Simplified Usage**:
```python
from utils.celery_helpers import format_celery_error

# Clean and simple:
response_data["error"] = format_celery_error(result.info)
```

**Risk**: ‚úÖ **NONE** - Pure refactoring

---

### 3.2 Simplify Database URL Sanitization

**File**: `database/utils.py:100-111`

**Current Code** (‚ùå NESTED CONDITIONALS):
```python
db_url = settings.database_url
if "@" in db_url:
    protocol, rest = db_url.split("://")
    if "@" in rest:
        credentials, host = rest.split("@")
        username = credentials.split(":")[0] if ":" in credentials else credentials
        db_url_sanitized = f"{protocol}://{username}:***@{host}"
    else:
        db_url_sanitized = db_url
else:
    db_url_sanitized = db_url
```

**Simplified Code** (‚úÖ EARLY RETURN):
```python
def sanitize_db_url(url: str) -> str:
    """
    Hide password in database URL for logging.

    Example:
        postgresql://user:password@host/db
        -> postgresql://user:***@host/db
    """
    if "@" not in url:
        return url

    try:
        protocol, rest = url.split("://", 1)
        credentials, host = rest.split("@", 1)
        username = credentials.split(":", 1)[0]
        return f"{protocol}://{username}:***@{host}"
    except ValueError:
        # Malformed URL, return as-is
        return url

# Usage:
db_url_sanitized = sanitize_db_url(settings.database_url)
```

**Benefits**:
- Early return pattern (more Pythonic)
- Explicit error handling
- Clearer intent with function name
- Single responsibility

**Risk**: ‚úÖ **NONE** - Pure refactoring

---

### 3.3 Create Shared Validation Utilities

**Problem**: User validation logic duplicated across files

**Current Duplicates**:

1. `api/routes/email.py` - Checks user ownership
2. `pipeline/steps/email_composer/db_utils.py:91-100` - Validates user exists
3. Similar patterns elsewhere

**Create Utility** (`utils/validators.py`):
```python
from uuid import UUID
from sqlalchemy.orm import Session
from models.user import User
from fastapi import HTTPException, status

def validate_user_exists(db: Session, user_id: UUID) -> User:
    """
    Validate that a user exists in the database.

    Args:
        db: Database session
        user_id: User UUID

    Returns:
        User object if found

    Raises:
        HTTPException: 404 if user not found
    """
    user = db.query(User).filter(User.id == user_id).first()
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"User not found: {user_id}"
        )
    return user

def validate_email_ownership(db: Session, email_id: UUID, user_id: UUID) -> Email:
    """
    Validate that an email belongs to the specified user.

    Returns:
        Email object if found and owned by user

    Raises:
        HTTPException: 404 if not found, 403 if not owned by user
    """
    email = db.query(Email).filter(Email.id == email_id).first()
    if not email:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Email not found: {email_id}"
        )
    if email.user_id != user_id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="You don't have permission to access this email"
        )
    return email
```

**Risk**: ‚ö†Ô∏è **LOW** - New utility, incremental adoption

---

### 3.4 Remove Pipeline Retry Duplication

**File**: `pipeline/steps/email_composer/main.py:230-283`

**Problem**: Manual retry loop duplicates agent's built-in retry mechanism

**Current Code** (‚ùå DUPLICATE RETRY LOGIC):
```python
# Agent already has retries configured!
agent = create_agent(model=self.model, retries=2, ...)

# But then we ALSO do manual retry loop:
max_retries = 3
for attempt in range(max_retries):
    try:
        result = agent.run(...)
        break
    except Exception as e:
        if attempt < max_retries - 1:
            continue
        else:
            raise
```

**Simplified Code** (‚úÖ TRUST AGENT RETRIES):
```python
# Just configure agent with appropriate retries:
agent = create_agent(
    model=self.model,
    retries=3,  # Agent handles retries internally
    ...
)

# Single call, agent handles retries:
result = agent.run(...)
```

**Risk**: ‚ö†Ô∏è **LOW** - Agent retry mechanism is already tested
- **Mitigation**: Verify agent retries work as expected
- **Testing**: Test with simulated API failures

---

## Phase 4: Best Practices & Code Quality

**Priority**: üü¢ MEDIUM
**Estimated Time**: 3 hours
**Risk Level**: Very Low
**Impact**: Medium (code clarity)

### 4.2 Add Missing Type Hints

**Files**:
- `database/utils.py` - Functions missing return types

**Current Code**:
```python
def init_db():  # ‚ùå No return type
    """Initialize database tables."""
    Base.metadata.create_all(bind=engine)

def drop_db():  # ‚ùå No return type
    """Drop all database tables."""
    Base.metadata.drop_all(bind=engine)

def reset_db():  # ‚ùå No return type
    """Reset database (drop and recreate)."""
    drop_db()
    init_db()
```

**Fixed Code**:
```python
def init_db() -> None:
    """Initialize database tables."""
    Base.metadata.create_all(bind=engine)

def drop_db() -> None:
    """Drop all database tables."""
    Base.metadata.drop_all(bind=engine)

def reset_db() -> None:
    """Reset database (drop and recreate)."""
    drop_db()
    init_db()
```

**Other Files to Check**:
- Any helper functions in `utils/`
- Pipeline step methods

**Risk**: ‚úÖ **NONE** - Type hints are documentation, don't affect runtime

---

### 4.3 Add Comprehensive Docstrings

Don't overdo the comments, keep comments simple and concise.

**File**: `database/base.py`

**Current Code** (‚ùå NO DOCSTRINGS):
```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from config.settings import settings

engine = create_engine(settings.database_url)
SessionLocal = sessionmaker(bind=engine)
Base = declarative_base()
```

**Improved Code** (‚úÖ WITH DOCSTRINGS):
```python
"""
Database configuration and SQLAlchemy setup.

This module provides the core database infrastructure:
- SQLAlchemy engine for connection pooling
- Session factory for database transactions
- Declarative base for ORM models
"""

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from config.settings import settings

# Database engine - handles connection pooling and execution
# Connection pool size controlled by SQLAlchemy defaults
engine = create_engine(
    settings.database_url,
    echo=False,  # Set to True for SQL query logging
    pool_pre_ping=True,  # Verify connections before using
)

# Session factory - creates new database sessions
# Use with dependency injection (Depends(get_db)) in FastAPI routes
SessionLocal = sessionmaker(
    bind=engine,
    autocommit=False,  # Explicit commits required
    autoflush=False,   # Explicit flush control
)

# Declarative base for ORM models
# All models should inherit from this base class
Base = declarative_base()
```

**Other Files Needing Docstrings**:
- `config/settings.py` - Document all settings
- Pipeline step classes - Document parameters and return values

**Risk**: ‚úÖ **NONE** - Documentation only

## Questions & Decisions

### Open Questions

1. **UUID Standardization**: Should we use `UUID` or `str` in Pydantic schemas?
   - **Recommendation**: Use `str` in API schemas, convert internally

2. **Timeout Values**: What's appropriate for each pipeline step?
   - **Recommendation**: Start at 60s, tune based on monitoring

3. **Logging Level**: Should startup messages be INFO or DEBUG?
   - **Recommendation**: INFO for key events, DEBUG for details

4. **Test Coverage**: What's the minimum acceptable coverage?
   - **Current**: Needs baseline measurement
   - **Target**: Maintain or improve current coverage

### Design Decisions

**Decision 1**: Remove auto-commit from context manager
- **Rationale**: Explicit is better than implicit (Zen of Python)
- **Trade-off**: Requires manual commits, but safer

**Decision 2**: Delete entire `/api/legacy/` directory
- **Rationale**: Not referenced anywhere, contains security issues
- **Trade-off**: Loses old code, but it's in git history

**Decision 3**: Standardize on structured logging
- **Rationale**: Production-ready observability
- **Trade-off**: More verbose than print(), but much more useful
